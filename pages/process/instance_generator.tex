\subsection{Generación de instancias aleatorias}
El método de generación de instancias aleatorias se basa en un sistema de instancias sintéticas
que se generan a partir de un conjunto de parámetros de entrada. En el siguiente paper \cite{pbrandimarte}
se define una tabla con diferentes rangos de valores para cada parámetro en cada conjunto de
tamaños de instancias. En nuestro caso, se va a utilizar tres conjuntos de tamaños de instancias
representados en la siguiente tabla.

\begin{table}[ht]
    \centering
    \begin{tabular}[t]{|l|ccc|}
        \hline
                  & Ins. Pequeña & Ins. Medianas & Ins. Grandes \\
        \hline
        Min. num Trabajos    & 3    & 5     & 10    \\
        Max. num Trabajos    & 5    & 10    & 20    \\
        Min. num Operaciones & 2    & 5     & 5     \\
        Max. num Operaciones & 5    & 10    & 10    \\
        Min. num Maquinas    & 2    & 4     & 8     \\
        Max. num Maquinas    & 4    & 8     & 16    \\
        \hline
    \end{tabular}
    \caption{Conjuntos de tamaños de instancias}
\end{table}

En este caso se va a almacenarlas las instancias una vez generadas para poder asegurar la reproducibilidad 
de los resultados, esto adicionalmente implica otros beneficios como el ahorro de tiempo de procesamiento
a la hora de entrar el modelo que se vera altamente beneficiado cuando en pasos posteriores se calcule
las rutas optimas de fabricación de las instancias. Estas conforman nuestro conjunto de datos de 
entrenamiento, de los cuales extraeremos una pequeña parte por cada grupo de instancias para formar
diferentes conjuntos de validación. 

\subsection{Modelos de programación matemático}
Los modelos de programación matemática son una herramienta muy poderosa para resolver problemas
de optimización, en este caso se va a utilizar una librería de código abierto llamada OR-Tools 
\cite{ortools} que esta desarrollada por Google y es utilizada para resolver problemas de optimización 
combinatoria. La librería proporciona algoritmos para resolver una amplia variedad de problemas 
de programación matemática, como problemas de programación lineal, programación entera mixta, 
programación de enteros, y otros problemas de optimización combinatoria.\medskip 

Dentro de la librería se encuentra un modulo llamado \textbf{CP-SAT} que es un modulo de programación
de restricciones que utiliza el algoritmo de búsqueda de satisfacción de restricciones (CS) para resolver
problemas de programación de tareas. Este modulo es el que se va a utilizar para resolver el problema y
dentro de la documentación \cite{ortools-jobshop} de la librería se encuentra un ejemplo de como 
aplicarlo de forma sencilla. La entrada de OR-Tools es una lista de tareas, donde cada tarea contiene
una lista de máquinas que pueden realizar la operación junto con el tiempo de procesamiento.\medskip

\begin{lstlisting}
    jobs_data = [                   
        [(0, 3), (1, 2), (2, 2)],   # Job0
        [(0, 2), (2, 1), (1, 4)],   # Job1
        [(1, 4), (2, 3)]            # Job2
    ]
   
    process_jobs(jobs_data)

    Output:
    Machine 0: [0,3] [3,5]
    Machine 1: [0,4] [4,6] [7,11]
    Machine 2: [5,6] [6,8] [8,11]
\end{lstlisting}

Este resultado muestra una configuración optima de fabricación, de la que se pueden extraer
adicionalmente los tiempos de inicio y fin de cada operación, una representación en forma de
diagrama de Gantt y el make span de la configuración. El make span es el tiempo total que se 
tarda en completar todas las operaciones de la configuración, y es el valor que se va a utilizar
para evaluar la precision de los modelos de deep learning. Con este valor ya seriamos capaces
de conformar los diferentes sets de validación, ya que para esta no es necesario como tal ningún
dato adicional. 

\subsection{Entrenamiento del modelo de deep learning}
\subsubsection{Arquitectura del modelo }
La arquitectura del modelo de deep learning se forma a partir de la combinación de tres 
modelos basados en redes neuronales de grafos que forman un único modelo que es capaz 
de adaptarse a los diferentes tipos de instancias que tenga que predecir. Normalmente en el
ensemble learning se utiliza diferentes técnicas como la votación o la media de los resultados
para elegir las diferentes acciones que se van a tomar, esto es debido a que en ese tipo de problemas
no suele haber una única solución correcta o a que no existe un criterio que permita 
elegir una solución sobre otra. En nuestro caso, debido al claro objetivo que es reducir 
el make span, se va a utilizar la solución que tenga el menor make span de entre las tres 
generadas por los modelos. Los tres modelos que se van a seleccionar son aquellos tres 
que mejor resultado hayan dado en la fase de validación.\medskip

A continuación, se puede ver como esta definido el modelo basado en redes neuronales de grafos.
Para este caso se ha están utilizando capas convolucionales GATv2Conv que son específicas para
el procesamiento de aristas dentro de grafos. Estas capas convolucionales pertenecen a la librería
de Pytorch Geometric \cite{pytorch-geometric} que es una librería de código abierto que proporciona
implementaciones de algoritmos de aprendizaje profundo sobre grafos. 

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.25]{normalmodel.png}
    \caption{Modelo basado en redes neuronales de grafos}
    \label{fig:basicmodel}
\end{figure}

Esta versión del modelo funciona como un agente de RL que recibe como entrada un grafo que representa
un estado del problema, y como salida devuelve la acción que debe tomar para avanzar al siguiente estado.
Para el entrenamiento, utilizaremos para entrenar esta arquitectura básica ya que es la que mejor
en términos de eficiencia para posteriormente aplicar el ensemble learning.

\subsubsection{Procesado de los datos de entrenamiento}
En la sección anterior se ha visto como se puede obtener una configuración optima de fabricación
a partir de una instancia del problema, pero para poder entrenar el modelo de deep learning es necesario
que los datos de entrenamiento estén en un formato que sea capaz de procesar el modelo. Para ello,
vamos a conformar un dataset que contenga por un lado un estado del problema y por otro lado la
acción que el experto ha tomado para resolverlo.\medskip

Una de las utilidades de la librería OR-Tools es que el resultado guarda en las operaciones
un atributo que representa en que orden han sido seleccionadas, por lo que es posible mediante 
una simple función de ordenamiento conseguir una sucesión de acciones para llegar a la solución.
Por ultimo, debido a que guardar el grafo directamente en el dataset no es posible debido a que
no es un tipo de dato que se pueda serializar fácilmente, se va a guardar una representación en forma de
matriz de adyacencia del grafo. Esta matriz de adyacencia representara las conexiones de tal modo que 
se pueda cargar y procesar de forma sencilla.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.47]{generate_train.png}
    \caption{Pipeline para generar el train.csv}
    \label{fig:trainingpipeline}
\end{figure}

\subsubsection{Funcion de entrenamiento}
Una vez que se ha generado el dataset de entrenamiento, se puede proceder a entrenar el modelo.
Se va a definir una función train que recibe como parámetros el modelo, el optimizador, el dataset
que hemos generado previamente y el tamaño del batch. Esta función se encarga de entrenar el modelo
y devolver el calculo del loss que se ha obtenido durante el entrenamiento.\medskip

\begin{figure}[ht]
\begin{lstlisting}
def train(model, optimizer, train_loader, batch_size):
    model.train()
    softmax = torch.nn.Softmax(dim=0)
    total_examples, total_loss = 0, 0

    for batch in train_loader:
        optimizer.zero_grad()
        action_prob = torch.Tensor([])
        result = model(batch)

        list_action_prob = []
        list_targets = []

        for i in range(batch["job"].batch[-1] + 1):
            action_probs = result[batch_index == i].T[0]
            action_prob = softmax(action_probs)
            list_action_prob.append(action_prob)
            list_targets.append(
                batch[("machine", "exec", "job")].y[batch_index == i]
            )

        loss = F.binary_cross_entropy(list_action_prob, list_targets)
        loss.backward()
        optimizer.step()

        total_examples += batch_size
        total_loss += float(loss) * batch_size

    return total_loss / total_examples 
\end{lstlisting}\medskip
    \caption{Train code example}
    \label{fig:traincode}
\end{figure}

Esta función es la responsable de efectuar el Imitation Learning, para ello carga en el
batch de entrenamiento los grafos que habíamos generado previamente y se le pasa al modelo para que
realice la predicción. Una vez que se tiene la predicción, se calcula el loss y se compara
con la solución que ha tomado el experto para ese estado. Una de las particularidades que
tiene el modelo es que la predicción que devuelve se realiza sobre el tensor que representa
la relación entre las operaciones y las maquinas, por lo que aunque aumente o disminuya 
el numero de operaciones o maquinas no sera necesario modificar el modelo, ya que este 
se adapta a diferentes dimensionalidades.

\subsubsection{Arquitectura del ensemble}
Una vez que se ha entrenado el modelo básico, se puede proceder a montar el ensemble.
Como se ha comentado anteriormente, el ensemble se va a componer de 3 modelos, cada uno
de ellos se va a ejecutar de forma independiente y se va a recuperar la solución que 
mejor desempeño haya tenido. A continuación se muestra la arquitectura del ensemble.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.38]{ensemblearc.png}
    \caption{Arquitectura del ensemble}
    \label{fig:ensemblearc}
\end{figure} 

De cara a un futuro, se podría plantear la posibilidad de añadir mas modelos al ensemble
incluso de diferentes tipos entre si. Por ejemplo, se podría añadir un modelo con 
distinto tipo de arquitectura o incluso un modelo que no sea de deep learning. Otra 
posibilidad también seria la de añadir un sistema de votación o stacking para que 
la acción que se tome sea la que mas votos haya obtenido entre los modelos. Se
podría realizar una primera pasada como la que se ha hecho en este trabajo y posteriormente
realizar una segunda pasada mediante un sistema de stacking en la que los pesos de los
modelos se calculen en base a su desempeño en la primera pasada.