\subsection{Optimización de Hiperparámetros}
La optimización de hiperparámetros \cite{hypertune} se refiere al proceso de ajustar los parámetros 
de entrenamiento y configuración de un modelo de Machine Learning con el objetivo de 
mejorar su desempeño. Los hiperparámetros son variables que no se aprenden automáticamente 
a partir de los datos, sino que deben ser configurados por el investigador.\medskip

En un modelo de Machine Learning, los hiperparámetros pueden incluir variables como 
la tasa de aprendizaje, la profundidad de la red neuronal, la cantidad de neuronas en 
cada capa, el tamaño del Batch, entre otros. El proceso de optimización implica la 
selección cuidadosa de los valores de los hiperparámetros que maximicen el rendimiento 
del modelo en un conjunto de datos de prueba. Esto generalmente se realiza mediante 
la búsqueda de un rango de valores posibles para los hiperparámetros y evaluando el 
rendimiento del modelo en cada combinación posible. La puesta a punto de los hiperparámetros 
es un aspecto importante del desarrollo de modelos, ya que una mala selección puede llevar a un rendimiento 
deficiente. Un modelo que esté bien optimizado puede mejorar significativamente su 
capacidad para hacer predicciones precisas y generalizar a datos nuevos y desconocidos.

\subsubsection{Optimización bayesiana}
La optimización bayesiana \cite{bayesianoptmization} utiliza un enfoque probabilístico para buscar el conjunto 
óptimo de hiperparámetros. En lugar de evaluar todas las combinaciones posibles de 
hiperparámetros, la optimización bayesiana utiliza una estrategia de búsqueda más 
inteligente que utiliza la información de iteraciones anteriores para buscar en el 
espacio de búsqueda de manera más eficiente. El algoritmo utiliza una función de subrogación que mide la incertidumbre del modelo 
en un conjunto de datos de prueba. La estrategia de optimización consiste en construir 
un modelo probabilístico a partir de la función objetivo y utilizarla para decidir qué hiperparámetros 
probar a continuación. En cada iteración, el modelo actualizado sugiere un conjunto de 
hiperparámetros que se espera que tengan una buena probabilidad de mejorar el rendimiento 
del modelo. El modelo se entrena con los nuevos hiperparámetros y se evalúa 
su rendimiento en el conjunto de prueba. Esta evaluación se utiliza para actualizar el 
modelo probabilístico, y se repite el proceso de búsqueda de hiperparámetros hasta 
que se encuentra una combinación que satisfaga el criterio de parada.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.29]{bayesiana.png}
    \caption{Proceso de optimización bayesiana}\label{fig:bayesiana}
\end{figure}

\subsubsection{Proceso de optimización con Optuna}
Optuna utiliza el método de optimización bayesiana para buscar el conjunto óptimo de
hiperparámetros. Además, mediante Optuna-Dashboard se puede visualizar el proceso de
optimización, la importancia de cada hiperparámetro, la relación entre los hiperparámetros
y llevar un registro de las mejores combinaciones de hiperparámetros encontradas. A 
continuación se muestra el listado de hiperparámetros:

\begin{table}[ht]
    \centering
    \begin{tabular}[ht]{l|c|c} 
        \textbf{Lista de Hiperparámetros} & \textbf{Rango de valores} & \textbf{Valor Óptimo}\\
        \hline
        \textbf{Número de instancias pequeñas} & 0 -- 20k & 20k\\
        \textbf{Número de instancias medianas} & 0 -- 20k & 10k\\
        \textbf{Número de instancias grandes}  & 0 -- 20k & 10k \\
        \textbf{Tasa de aprendizaje} & 0.00001 -- 0.001 & 0.0008\\
        \textbf{Número de épocas} & 5 -- 35 & 30 \\ 
        \textbf{Número de episodios} & 1 -- 3 & 2 \\
        \textbf{Tamaño del Batch} & 64, 128, 256 & 64\\
        \textbf{Canales ocultos} & 100 -- 300 & 200 \\
        \textbf{Número de capas ocultas} & 1 -- 6 & 1 \\
    \end{tabular}
    \caption{Lista de hiperparámetros}
    \label{tab:hyperparams}
\end{table}

Esta lista de hiperparámetros se obtuvo a partir de múltiples experimentos. En cada 
experimento se realizaban tres entrenamientos con los mismos hiperparámetros y luego
se promediaba el resultado de cada métrica, para así obtener un resultado más estable.
El objetivo de estos experimentos era minimizar la función objetivo y se realizaron
un total de 300 pruebas con diferentes combinaciones. En la figura \ref{fig:experiments}
se puede observar la visualización de los experimentos realizados y como progresa la
configuración de los hiperparámetros, aquí los puntos azules representan los experimentos
realizados y la linea roja representa la mejor combinación de hiperparámetros encontrada
hasta el momento.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.31]{experiments.png}
    \caption{Visualización de la experimentación de hiperparámetros}
    \label{fig:experiments}
\end{figure}

Una de las ventajas de utilizar Optuna es que se puede visualizar la importancia de cada
hiperparámetro, en la figura \ref{fig:importance} se puede observar que los hiperparámetros
que mayor impacto tienen en el rendimiento del modelo son la tasa de aprendizaje, el número
de instancias pequeñas y el número de capas ocultas. Este conocimiento ha traído consigo
una mejora en el rendimiento del modelo, se ha visto que el número optimo de capas ocultas 
es de uno lo que ha supuesto una mejora en la velocidad del modelo ya que no solo se reduce 
el tiempo de entrenamiento sino que también se reduce el tiempo de procedimiento a la hora 
de realizar predicciones.

\begin{figure}[ht!]
    \centering
    \includegraphics[scale=0.31]{importance.png}
    \caption{Importancia de los hiperparámetros}
    \label{fig:importance}
\end{figure}

Queda claro que la tasa de aprendizaje es el hiperparámetro más importante, seguido
del número de instancias pequeñas y el número de capas ocultas. Al parecer, la hipótesis
inicial que se tenía sobre que las redes de grafos debido a su naturaleza son capaces de
aprender con instancias pequeñas y generalizar a instancias más grandes es cierta. Ya que
por mucho que se entrenase con instancias grandes, el rendimiento del modelo no mejoraba
significativamente y en cambio en el aumento de instancias pequeñas si se veía una mejora
en el rendimiento del modelo.
